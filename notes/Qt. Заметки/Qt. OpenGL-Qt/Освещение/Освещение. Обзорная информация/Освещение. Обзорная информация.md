---


---
---

Данная заметка является переводом [вот этой статьи](https://learnopengl.com/Lighting/Basic-Lighting).

---

## Основные типы освещения

Освещение в реальном мире - это сложнейший процесс, который зависит от слишком большого количества факторов, которые мы просто не в силах вычислять, на наших ограниченых компьютерах.

Освещение же в **OpenGL** устроено таким образом, что оно опроксимирует реальное, используя упращенные инструменты из физики, которые поддаются нашему пониманию и исчислению. Одна из таких физических моделей, которая часто используется в графике - это [Световая Модель Фонга](https://en.wikipedia.org/wiki/Phong_reflection_model). Основные компоненты, из которых состоит данная модель - это фоновый (_ambient_), рассеянный/диффузный (_diffuse_) и бликовый (_specular_):

![[basic_lighting_phong.png]]

- _**Фоновый свет**_ - даже если в простанстве очень темно, всегда будет хоть немного света (очень дальняя луна, отражение света солнца и тд), поэтому объекты почти полностью темные, но при этом все ещё немного разлечимы.
- _**Рассеяный свет**_ - иммитирует воздействие на объект направленного источника света. Это наиболее визуально значимый компонент освещение (используется повсеместно). Чем большая часть объекта повернута к свету, тем более она будет освещена.
- _**Бликовый свет**_ - иммитирует яркое белое пятно, сгусток света, которое появляется на блестящих объектах, типа металла. По цвету зеркальные блики всегда ближе к цвету источника света, чем к бликующему объекту.

На сценах очень часто используется сразу несколько типов цветов.

## Фоновый свет

Обычно свет исходит не только от одного источника - а сразу от многих, даже если мы не видим их напрямую (Солнце за тучами, к пример). Он из самых важных свойств света заключается в том, что он постоянно рассеивается или отражается сразу во множество направлений от объектов, достигая таких мест, где сам источник света - может быть полностью невидим. Таким образом, свет может отражаться от других поверхностей и оказывать косвенное влияние на освещение объекта. Алгоритмы, которые учитывают именно это свойство света называются _**Глобальным Освещением**_, но их крайне дорого реализовывать.

А так как мы хотим сразу прыгнуть в прикладную часть - начнем с самого простого алгоритма _**Глобального Освещения**_ (и по факту, самого дешевого) - _**Фонового Света**_. Как мы помним из прошлой заметки - мы добавили немного констатного света (от нашего источника) в результирующий цвет объекта в шейдере.

Таким же образом мы добавим и Фоновый Свет в наш шейдер. Логика следующая - взять немного цвета света, умножить ее на константное значение _**Фонового**_ множителя (его лучше брать небольшим) и все это использовать для фрагментарного получения цвета и дальнейшего намазывания его на куб:

```C++

void main()
{
    float ambientStrength = 0.1;
    vec3 ambient = ambientStrength * lightColor;

    vec3 result = ambient * objectColor;
    FragColor = vec4(result, 1.0);
}  
```

## Рассеяный свет

Чем более перпендикулярно направлению лучей источника света расположены фрагменты объекта, тем большую яркость им придает диффузная составляющая освещения. Чтобы лучше понять диффузное освещение, взгляните на следующее изображение:

![[diffuse_light.png]]

Слева от объекта у нас расположен источник света - сильно упрощая, светит он сейчас на 1 фрагмент. Нам надо померить с каким углом световой луч доходит до фрагмента. Если свет будет стоять перпендикулярно к фрагменту - то он будет максимально возмножно освещен.

Что бы померить угол между лучом света и фрагментом - нам пригодится такая сущность, как [вектор нормали](Трансформации Векторов Нормали). Это вектор который перпеникулярен вертексной плоскости, которую мы рассматриваем. Угол $\theta$﻿ может быть легко вычислен при помощи _Скалярного_ _Произведения_.

Как мы помним - чем меньше значение угла между двумя единичными векторами, тем более _Скалярное Произведение_ стремится к значению $1.0$﻿. Когда угол между этими векторами становится $90^{\circ}$﻿ _Векторное Произведение_ оборачивается в нуль. Это же правило касается и угла $\theta$﻿, чем больше значение $\theta$﻿, тем меньше свет влияет на конечный цвет фрагмента.

- **Не забываем!**
    
    Что бы получить только значение косинуса угла между двумя единичными векторами - мы должны каждый раз нормализовывать эти вектора, иначе _Векторное Произведение_ будет больше $cos\ \theta$﻿.
    

То есть результирующее скалярное произведение возвращает число, благодаря которому мы можем посчитать воздействие света на фрагмент.

В итоге нам нужно для определения Рассеяного Света:

- _**Вектор Нормали**_ - вектор перпендикулярный поверхности вертекса.
- _**Направление Луча Света**_ - вектор направления, который представляет собой разницу между **позицией источника света** и позицией **фрагмента**.

### Вектора Нормали

Вектор нормали - это единичный вектор, который перпендикулярен поверхности вертекса. Так как сам по себе вектекс не образовывает поверхность (это просто точка в пространстве) то мы обращаем внимание на рядом стоящие вертексы, для определения направления нормали. Можно, конечно, использовать небольшой трюк для вычисления векторов нормали куба - используя Векторное Произведение, но так как куб - это очень простая фигура, мы просто запехнем их в данные о вертексе.

```C++
// General vertices
const std::vector vertices = {
    // POSITIONS:          // TEX COORDS: // NORMALS:
    // Top rectangle vertices + texture coordinate + normals
    -0.5F,  0.5F, -0.5F,   0.0F, 1.0F,    0.0F,  1.0F,  0.0F, // top left         [0]
     0.5F,  0.5F, -0.5F,   1.0F, 1.0F,    0.0F,  1.0F,  0.0F, // top right        [1]
    -0.5F,  0.5F,  0.5F,   0.0F, 0.0F,    0.0F,  1.0F,  0.0F, // bottom left      [2]
     0.5F,  0.5F,  0.5F,   1.0F, 0.0F,    0.0F,  1.0F,  0.0F, // bottom right     [3]
    // Bottom rectangle vertices + texture coordinate     
    -0.5F, -0.5F, -0.5F,   0.0F, 1.0F,    0.0f, -1.0f,  0.0f, // top left         [4]
     0.5F, -0.5F, -0.5F,   1.0F, 1.0F,    0.0f, -1.0f,  0.0f, // top right        [5]
    -0.5F, -0.5F,  0.5F,   0.0F, 0.0F,    0.0f, -1.0f,  0.0f, // bottom left      [6]
     0.5F, -0.5F,  0.5F,   1.0F, 0.0F,    0.0f, -1.0f,  0.0f, // bottom right     [7]
    // Left side rectangle vertices + texture coordinate  
    -0.5F,  0.5F, -0.5F,   0.0F, 1.0F,   -1.0f,  0.0f,  0.0f, // top left         [8]
    -0.5F,  0.5F,  0.5F,   1.0F, 1.0F,   -1.0f,  0.0f,  0.0f, // top right        [9]
    -0.5F, -0.5F, -0.5F,   0.0F, 0.0F,   -1.0f,  0.0f,  0.0f, // bottom left      [10]
    -0.5F, -0.5F,  0.5F,   1.0F, 0.0F,   -1.0f,  0.0f,  0.0f, // bottom right     [11]
    // Right side rectangle vertices + texture coordinate  
     0.5F,  0.5F,  0.5F,   0.0F, 1.0F,    1.0f,  0.0f,  0.0f, // top left         [12]
     0.5F,  0.5F, -0.5F,   1.0F, 1.0F,    1.0f,  0.0f,  0.0f, // top right        [13]
     0.5F, -0.5F,  0.5F,   0.0F, 0.0F,    1.0f,  0.0f,  0.0f, // bottom left      [14]
     0.5F, -0.5F, -0.5F,   1.0F, 0.0F,    1.0f,  0.0f,  0.0f, // bottom right     [15]
    // Back side rectangle vertices + texture coordinate  
    -0.5F,  0.5F, -0.5F,   0.0F, 1.0F,    0.0f,  0.0f, -1.0f, // top left         [16]
     0.5F,  0.5F, -0.5F,   1.0F, 1.0F,    0.0f,  0.0f, -1.0f, // top right        [17]
    -0.5F, -0.5F, -0.5F,   0.0F, 0.0F,    0.0f,  0.0f, -1.0f, // bottom left      [18]
     0.5F, -0.5F, -0.5F,   1.0F, 0.0F,    0.0f,  0.0f, -1.0f, // bottom right     [19]
    // Front side rectangle vertices + texture coordinate  
    -0.5F,  0.5F,  0.5F,   0.0F, 1.0F,    0.0f,  0.0f,  1.0f, // top left         [20]
     0.5F,  0.5F,  0.5F,   1.0F, 1.0F,    0.0f,  0.0f,  1.0f, // top right        [21]
    -0.5F, -0.5F,  0.5F,   0.0F, 0.0F,    0.0f,  0.0f,  1.0f, // bottom left      [22]
     0.5F, -0.5F,  0.5F,   1.0F, 0.0F,    0.0f,  0.0f,  1.0f, // bottom right     [23]
};
```

Так же стоит обновить вертексные шейдеры, добавив в них строку:

```C++
layout (location = 2) in vec3 aNormal;
```

И обновить задание атрибутов:

```C++
// Normals attribute
if (!opengl_utils::Execute<bool>(
		m_pData->f.get(),
		&QOpenGLFunctions::glVertexAttribPointer,
		2, // Same as (location = 2) in Vertex Shader
		3, // Size of Vertex Attribute. Only 3 Vertices like in vec3
		GL_FLOAT,                                  // Type of data in 
		GL_FALSE,                                  // Should data be normalized
		MEMORY_STRIDE,                             // Stride
		reinterpret_cast<void*>(5 * sizeof(float)) // Offset 20
	)
) 
{
	return opengl_utils::locals::PrintLine<bool>(__FILE__, __LINE__);
}
if (!opengl_utils::Execute<bool>(
		m_pData->f.get(), 
		&QOpenGLFunctions::glEnableVertexAttribArray, 
		2 /*Same as (location = 2) in Vertex Shader*/
	)
)
{
	return opengl_utils::locals::PrintLine<bool>(__FILE__, __LINE__);
}
```

Кстати, код написанный выше - мы не будем вставлять в объект лампы, тк нам надо что бы в лампе (_куб, который отвечает за освещение_) просто пропускались чанки с данными о нормалях.

Может показаться что такой подход не очень эффективен - хранить дополнительный данные в вертексах, но как показывает практика это будет куда эффективнее, чем создавать еще один отдельный `VBO` под лампу.

Нормали из вершинного шейдера просто прокидываем в фрагментарный:

```C++
\#version 460 core

layout (location = 0) in vec3 aPosition;
layout (location = 1) in vec2 aTextureCoordinate;
layout (location = 2) in vec3 aNormal;

out vec2 outTextureCoordinate;
out vec3 outNormal;

uniform mat4 modelMatrix;
uniform mat4 viewMatrix;
uniform mat4 projectionMatrix;

uniform vec3 offsets[30];

void main()
{
    gl_Position 
        = projectionMatrix 
        * viewMatrix 
        * modelMatrix 
        * vec4(
            aPosition.x + offsets[gl_InstanceID].x, 
            aPosition.y + offsets[gl_InstanceID].y, 
            aPosition.z + offsets[gl_InstanceID].z, 
            1.0
        );
    
    outTextureCoordinate = aTextureCoordinate;
    outNormal = aNormal;
}
```

Ну и не забываем принять эти данные в Фрагментарном шейдере всех кубов:

```C++
in vec3 Normal;
```

### Вычисления диффузного (рассеяного) цвета

Теперь в нашем вертексе присутсвует информация о нормалях, но нам все еще не хватает позиции света и фрагментарной позиции вертекса. Тк позиция света это очень часто - константа, зададим ее через `uniform`:

```C++
uniform vec3 lightPos;
```

И потом можем обновлять это позицию либо в цикле рендереинга, либо, как в нашемс, случае - лучше это делать отдельно, тк позиция не меняется.

```C++
// Setting light position:
if (!pLightProgramHandler->setFloatVec3Uniform(
        QStringLiteral("lightPos"), 
        glm::value_ptr( lightPosition )
    )
)
{
    return opengl_utils::locals::PrintLine<bool>(__FILE__, __LINE__);
}
```

Из-за того, что все вычисления по свету будут проводиться в _**Мировых Координатах**_ мы хотим что бы позиции вершин тоже были в _**Мировых Координатах**_, а для этого нам надо перемножить их на _Матрицу Модели_.

```C++
#version 460 core

layout (location = 0) in vec3 aPosition;
layout (location = 1) in vec2 aTextureCoordinate;

out vec2 outTextureCoordinate;
out vec3 outFragmentPosition;

uniform mat4 modelMatrix;
uniform mat4 viewMatrix;
uniform mat4 projectionMatrix;
uniform vec3 offsets[30];

void main()
{
    gl_Position 
        = projectionMatrix 
        * viewMatrix 
        * modelMatrix 
        * vec4(
            aPosition.x + offsets[gl_InstanceID].x, 
            aPosition.y + offsets[gl_InstanceID].y, 
            aPosition.z + offsets[gl_InstanceID].z, 
            1.0
        );
    
    outTextureCoordinate = aTextureCoordinate;
    outFragmentPosition = vec3(modelMatrix * vec4(aPosition, 1.0));
}
```

И потом пропихнем это значение в фрагментарный шейдер:

```C++
in vec3 outFragmentPosition;  
```

Данная переменная будет интерполирована из Мировых Координат треугольника, что бы сформировать вектор `outFragmentPosition`, который представляет собой фрагмент в Мировых Координатах. Теперь мы мы можем приступить к непосредственным расчетам рассеяного света.

Первое что нам надо найти - вектор направления между источником света и позицией фрагмента. Как и ранее в  $LookAt$﻿ мы знаем, что вектор направления рассчитывается при помощи вычитания из Смотрящего позицию таргета - и дальнейшая нормализация. Ну и заодно, что бы не было артефактов - нормализуем читающиеся из памяти нормали:

```C++
vec3 normalVector = normalize(outNormal);
vec3 lightDirection = normalize(lightPosition - outFragmentPosition);
```

- **Заметка про вычисление света**
    
    При рассчете света - мы обычно совершенно не переживаем ни о величине вектора, не о его положении в пространстве. По факту нас только интересует направление, собсвенно поэтому большей частью все вычисления связанные со светом происходят между единичными (нормализованными) векторами.
    

Далее мы вычисляем скаляр влияния цвета диффузного света, на выхлопной цвет шейдера:

```C++
float diffuseScalar = max(dot(normalVector, lightDirection), 0.0);
vec3 diffuseLightColor = diffuseScalar * lightColor;
```

Если угол между этими двумя векторами будет больше чем $90^{\circ}$﻿ тогда результат Векторного Произведения будет отрицательным - и мы получим отрицательную компоненту. Именно что бы этого не произошло мы используем функцию `max()`, которая ограничевает такую возиожность. Обратим внимание, что мы стараемся избегать конструкций типа `if(dot < 0.0)`, так как все ифы в шейдерах - плохой тон, в плане оптимизации. Так же это делается из-за того, что свет для негативных цветов не определен, а значит лучше просто не допускать возможности его появления.

Теперь смешаем прошлый эмбиент свет с нынешним диффузным:

```C++
vec3 resultingColor = (ambientLightColor + diffuseLightColor) * objectColor;
FragmentColor = vec4(resultingColor, 1.0);  
```

### Одна последняя штука

В прошлой секции мы прокинули нормальный вектор напрямую из вертексного шейдера в фрагментарный. Но при этом все вычисления в фрагментарном шейдере производились в _**Мировых Координатах**_, а не должны ли мы прегнать эти вектора также в _**Мировые Координаты**_? Конечно должны, но это немного не очевидный процесс.

Во-первых все нормали - это всего лишь вектора направления и они не представляют никаких реальных позиций в пространстве.

Во-вторых у нормалей нету [[Гомогенные Координаты]]. А это значит что трансляция на них не подействует. Поэтому если мы хотим умножить нормали на Матрицу Модели - нам потребуется убрать часть в матрице, которая отвечает за трансляцию (это кусок 3 на 3 в левой части матрицы. Кстати мы можем задать $w$﻿ координату нулем и просто умножить это на матрицу 4 на 4).

Если Матрицв Модели импользуется при неравномерном масштабировании, то вершина будет изменяться и нормаль больше не будет перпендикулярной к плоскости:

![[basic_lighting_normal_transformation.png]]

А занчит каждый раз, когда мы применяем неравномерное масштабирование (при равномерном - изменяется лишь значение величины вектора, и это великолепно фиксится нормализацией) то вектор будет не перпендикулярен к плоскости.

Трюк, что бы пофиксить данную проблему заключается в том, что бы использовать другую _**Матрицу Модели**_, и несколько линейных операций для избавления от эффекта неправильного скалирования. [[Трансформации Векторов Нормали]] эти преобразования рассписаны более подробно.

_Нормализованная Матрица_ определяется как “Транспонированная обратная левая часть, имеющая размер 3 на 3, _Матрицы Модели_”. Кстати, большая часть ресурсов определяет _Нормализованную Матрицу_ как образованную от _Матрицы Модель/Представление_, но так как мы все еще работаем с _**Мировыми Координатами**_ (А не с Координатами Наблюдателя) - мы будем получать её из _Матрицы Модели_.

В вертексном шейдере мы можем сгенерировать _Нормализованную Матрицу_ испольозуя функции `inverse` и `transpose` . Лучше всего это делать на **CPU**, тк вычисление обратной матрицы - это крайне затратная операция для **GPU**. Поэтому так и поступим:

Вертексный шейдер:

```C++
\#version 460 core

layout (location = 0) in vec3 aPosition;
layout (location = 1) in vec2 aTextureCoordinate;
layout (location = 2) in vec3 aNormal;

out vec2 outTextureCoordinate;
out vec3 outNormal;
out vec3 outFragmentPosition;

uniform mat4 modelMatrix;
uniform mat4 viewMatrix;
uniform mat4 projectionMatrix;
uniform mat3 normalizeModelMatrix;

uniform vec3 offsets[30];

void main()
{
    gl_Position 
        = projectionMatrix 
        * viewMatrix 
        * modelMatrix 
        * vec4(
            aPosition.x + offsets[gl_InstanceID].x, 
            aPosition.y + offsets[gl_InstanceID].y, 
            aPosition.z + offsets[gl_InstanceID].z, 
            1.0
        );
    
    outTextureCoordinate = aTextureCoordinate;
    
    outNormal 
        = normalizeModelMatrix 
        * vec3(
            aNormal.x + offsets[gl_InstanceID].x, 
            aNormal.y + offsets[gl_InstanceID].y, 
            aNormal.z + offsets[gl_InstanceID].z
        );
    
    outFragmentPosition = vec3(modelMatrix * vec4(aPosition, 1.0));
}
```

Фрагментарный шейдер:

```C++
\#version 460 core

in vec2 outTextureCoordinate;
in vec3 outNormal;
in vec3 outFragmentPosition;

uniform sampler2D inputTextureContainer;
uniform sampler2D inputTextureBubs;
uniform float textureRatio;

uniform vec3 lightPosition;
uniform vec3 objectColor;
uniform vec3 lightColor;

out vec4 FragmentColor;

void main()
{     
    // Ambient light formula:
    float ambientStrength = 0.1;
    vec3 ambient = ambientStrength * lightColor;
    vec3 ambientLightColor = ambient * objectColor;

    // Diffuse light formula:
    vec3 normalVector = normalize(outNormal);
    vec3 lightDirection = normalize(lightPosition - outFragmentPosition);
    float diffuseScalar = max(dot(normalVector, lightDirection), 0.0);
    vec3 diffuseLightColor = diffuseScalar * lightColor;

    vec3 resultingColor = (ambientLightColor + diffuseLightColor) * objectColor;

    FragmentColor = vec4(resultingColor, 1.0);  
}
```

Выставляем нормализованую матрицу:

```C++
auto transformedModelMatrix = model;
transformedModelMatrix = glm::transpose(glm::inverse(transformedModelMatrix));
auto normalizedModelMatrix = glm::mat3(transformedModelMatrix);
if (!pObjectProgramHandler->setFloatMatrix3Uniform(
        QStringLiteral("normalizeModelMatrix"), 
        glm::value_ptr(normalizedModelMatrix)
    )
)
{
    return opengl_utils::locals::PrintLine<bool>(__FILE__, __LINE__);
}
```

## Зеркальное Освещение

По аналогии с рассеяным освещением, зеркальное базируется на приципе поиска направления света и нормалей объекта, но сюда добавляется еще и 3ий компонент - это направление откуда смотрит и позиция где находится Наблюдатель. При этом зеркальный свет основан буквально на умениях объекта отражать свет. Если думать о объекте, как о зеркале то зеркальное освещение будет тем сильнее, чем больше света отражается от поверхности:

![[basic_lighting_specular_theory.png]]

Мы вычисляем вектор отражения, отражая направление света около нормали. Затем мы вычисляем угловое расстояние между этим отраженным вектором и Наблюдателем. Чем меньше угол между ними, тем больше зеркальное освещение воздействует на цвет фрагмента. В результате, мы получаем подчеркивание света (пятно цвета света) когда смотрим по направлению света через объект.

- Заметки на полях
    
    Мы выбираем подход - где расчеты света будут происходить в Мировых Координатах, но часто люди препочитают считать освещение в _**Пространстве Вида**_. _**Пространство Вида (Камерв)**_ имеет свои преимущества - например то, что наблюдатель всегда находится в точке $(\textcolor{\#FF0000}{0}, \textcolor{\#00FF00}{0}, \textcolor{\#0000FF}{0})$﻿ поэтому нам даже не надо передавать эти значения. Но вычисление света в _**Мировых Координатах**_ - более интуитивное занятее при обучении. Но если хочется иожно и сейчас засунуть вычисления свет а Пространство Вида - надо будет только не забыть трансформировать все вектора при помощи _Матрицы Вида_ (и не забыть про трансформацию Нормали).
    

Поэтому добавим в шейдер кубов- позицию _Камеры_.

```C++
uniform vec3 viewPosition;
```

Ну и соответственно добавим заполнение этого вектора на каждую итерацию цикла отрисовки:

```C++
glm::vec3 currentCameraPosition = m_pData->pCamera->position();
if (!m_pData->pObjectProgramHandler->setFloatVec3Uniform(
        QStringLiteral("currentCameraPosition"), 
        glm::value_ptr(currentCameraPosition)
    )
)
{
    return opengl_utils::locals::PrintLine<void>(__FILE__, __LINE__);
}
```

Теперь определеим интенсивность отражения:

```C++
float specularStrength = 0.5;
```

Определим вектор направления взгляда Наблюдателя:

```C++
vec3 viewDirection = normalize(currentCameraPosition - outFragmentPosition);
vec3 reflectDirection = reflect(-lightDirection, normalVector);
```

Обратим внимание, что мы применил отрицание к переменной `lightDirection`, так как функция `reflect` ожидает на вход первым аргумент - точку **откуда пришел** свет к положению фрагмента, но вектор `lightDirection` сейчас указывает в другую сторону, то есть от фрагмента к источнику (направление зависит от порядка вычитания векторов, которое мы делали при вычислении вектора `lightDirection`). Поэтому, для получения правильного вектора отражения, мы меняем его направление на противоположное посредством инверсии вектора `lightDirection`. Предполагается, что второй аргумент должен быть единичной длинны, и мы передаем нормализованный вектор `normalVector`.  
Остается только вычислить компонент зеркального блика. Это выполняется по следующей формуле:  

```C++
    float specularScalar = pow(max(dot(viewDirection, reflectDirection), 0.0), 32);
    vec3 specularLight = specularStrength * specularScalar * lightColor;
```

Сначала вычисляется скалярное произведение векторов отражения и направления взгляда (с отсевом отрицательных значений), а затем результат возводится в 32-ю степень. Константное значение 32 задает силу блеска. Чем больше это значение, тем сильнее свет будет отражаться, а не рассеиваться, и тем меньше станет размер пятна блика. Ниже вы можете видеть изображение, демонстрирующее воздействие различных значений блеска на внешний вид объекта:

![[basic_lighting_specular_shininess.png]]

Мы не хотим, чтобы компонент зеркальных бликов слишком выделялся,  
поэтому оставим показатель степени равным 32. Остается только сложить  
полученную величину вместе с компонентами фонового и рассеянного  
освещения, после чего умножить результат на цвет объекта:  

```C++
// Result
vec3 resultingColor = (ambientLightColor + diffuseLightColor + specularLight) * objectColor;
FragmentColor = vec4(resultingColor, 1.0);  
```